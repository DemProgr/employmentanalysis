# hh_parser.py - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–∞—Ä—Å–µ—Ä–∞
import requests
import pandas as pd
import numpy as np
import time
import random
import re
from datetime import datetime, timedelta
import logging
from pathlib import Path
import sys
import json

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from config import BELARUS_CONFIG

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HHApiParser:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Å–±–æ—Ä–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å HeadHunter"""
    
    def __init__(self):
        self.base_url = "https://api.hh.ru"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json',
            'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8'
        })
        self.fallback_data = []  # –†–µ–∑–µ—Ä–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–æ–∫
    
    def search_vacancies(self, search_query="", area=16, per_page=50, pages=2):
        """–ü–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ API HH —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        all_vacancies = []
        
        for page in range(pages):
            try:
                logger.info(f"üîç –ü–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π: '{search_query}', —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page + 1}")
                
                params = {
                    'text': search_query,
                    'area': area,  # 16 - –ë–µ–ª–∞—Ä—É—Å—å
                    'page': page,
                    'per_page': per_page,
                    'only_with_salary': False,  # –ò–∑–º–µ–Ω–∏–ª–∏ –Ω–∞ False —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª—å—à–µ –≤–∞–∫–∞–Ω—Å–∏–π
                    'search_field': 'name'  # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö
                }
                
                response = self.session.get(f"{self.base_url}/vacancies", params=params, timeout=15)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
                if response.status_code != 200:
                    logger.warning(f"‚ö†Ô∏è API –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status_code}")
                    continue
                
                data = response.json()
                vacancies = data.get('items', [])
                
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page + 1}")
                
                for vacancy in vacancies:
                    try:
                        vacancy_data = self.parse_vacancy(vacancy)
                        if vacancy_data and vacancy_data.get('name'):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ
                            all_vacancies.append(vacancy_data)
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
                        continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã API
                if page >= data.get('pages', 1) - 1:
                    break
                    
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API
                time.sleep(0.3)
                
            except requests.exceptions.RequestException as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")
                break
            except Exception as e:
                logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                break
        
        return pd.DataFrame(all_vacancies) if all_vacancies else pd.DataFrame()
    
    def parse_vacancy(self, vacancy):
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            vacancy_id = vacancy.get('id', f"unknown_{int(time.time())}")
            name = vacancy.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ').strip()
            
            if not name or name == '–ù–µ —É–∫–∞–∑–∞–Ω–æ':
                return None
                
            company_info = vacancy.get('employer', {})
            company = company_info.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
            
            # –ó–∞—Ä–ø–ª–∞—Ç–∞
            salary_data = vacancy.get('salary')
            salary_from = salary_data.get('from') if salary_data else None
            salary_to = salary_data.get('to') if salary_data else None
            salary_currency = salary_data.get('currency', 'RUR') if salary_data else 'RUR'
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BYN
            salary_avg = self.calculate_avg_salary(salary_from, salary_to)
            salary_avg_byn = self.convert_to_byn(salary_avg, salary_currency) if salary_avg else None
            
            # –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
            experience = vacancy.get('experience', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω')
            
            # –ù–∞–≤—ã–∫–∏
            key_skills = self.extract_skills(vacancy)
            
            # –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ
            area_info = vacancy.get('area', {})
            area = area_info.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
            
            # –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            published_at = vacancy.get('published_at', '')
            
            # –û–ø–∏—Å–∞–Ω–∏–µ
            description = self.clean_description(vacancy.get('description', ''))
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            category = self.determine_category(name, description)
            
            vacancy_data = {
                'id': f"hh_{vacancy_id}",
                'name': name,
                'company': company,
                'category': category,
                'salary_from': salary_from,
                'salary_to': salary_to,
                'salary_currency': salary_currency,
                'salary_avg': salary_avg,
                'salary_avg_byn': salary_avg_byn,
                'experience': experience,
                'employment': vacancy.get('employment', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞'),
                'schedule': vacancy.get('schedule', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                'description': description[:500] if description else '',  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                'key_skills': key_skills,
                'skills_count': len(key_skills),
                'area': area,
                'published_at': published_at,
                'alternate_url': vacancy.get('alternate_url', ''),
                'archived': vacancy.get('archived', False),
                'source': 'hh_api'
            }
            
            return vacancy_data
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy.get('id', '')}: {e}")
            return None
    
    def calculate_avg_salary(self, salary_from, salary_to):
        """–†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π –∑–∞—Ä–ø–ª–∞—Ç—ã"""
        try:
            if salary_from and salary_to:
                return (salary_from + salary_to) / 2
            elif salary_from:
                return salary_from
            elif salary_to:
                return salary_to
            return None
        except:
            return None
    
    def convert_to_byn(self, amount, original_currency):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ BYN (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –∫—É—Ä—Å—ã)"""
        try:
            if not amount:
                return None
                
            conversion_rates = {
                'RUR': 0.035,  # RUB to BYN
                'RUB': 0.035,  # RUB to BYN
                'USD': 3.2,    # USD to BYN
                'EUR': 3.4,    # EUR to BYN
                'BYR': 1,      # –°—Ç–∞—Ä—ã–µ BYN
                'BYN': 1       # –¢–µ–∫—É—â–∏–µ BYN
            }
            
            rate = conversion_rates.get(original_currency, 1)
            converted = amount * rate
            
            # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ 50
            return round(converted / 50) * 50
        except:
            return None
    
    def extract_skills(self, vacancy):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏"""
        skills = []
        
        try:
            # –ò–∑ –∫–ª—é—á–µ–≤—ã—Ö –Ω–∞–≤—ã–∫–æ–≤
            if 'key_skills' in vacancy:
                skills.extend([skill['name'] for skill in vacancy['key_skills']])
            
            # –ò–∑ –æ–ø–∏—Å–∞–Ω–∏—è (–±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑)
            description = (vacancy.get('snippet', {}).get('requirement', '') + 
                          ' ' + vacancy.get('description', '')).lower()
            
            # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            common_skills = {
                'programming': ['python', 'java', 'javascript', 'c#', 'php', 'ruby', 'go', 'sql'],
                'web': ['html', 'css', 'react', 'vue', 'angular', 'node.js', 'django', 'flask'],
                'devops': ['docker', 'kubernetes', 'aws', 'linux', 'git', 'jenkins'],
                'databases': ['postgresql', 'mongodb', 'mysql', 'redis'],
                'tools': ['git', 'jira', 'confluence', 'figma', 'photoshop']
            }
            
            for category, skill_list in common_skills.items():
                for skill in skill_list:
                    if skill in description and skill not in skills:
                        skills.append(skill.title())
            
            return list(set(skills))[:8]  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏, –º–∞–∫—Å–∏–º—É–º 8
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤: {e}")
            return []
    
    def clean_description(self, description):
        """–û—á–∏—Å—Ç–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è –æ—Ç HTML —Ç–µ–≥–æ–≤"""
        try:
            if not description:
                return ""
            # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
            clean = re.compile('<.*?>')
            cleaned = re.sub(clean, '', description)
            # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            return cleaned
        except:
            return ""
    
    def determine_category(self, title, description):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
        try:
            text = (title + ' ' + description).lower()
            
            category_keywords = {
                '–ò–¢': [
                    '—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç', 'developer', 'software', 'it', '–∞–π—Ç–∏',
                    'python', 'java', 'javascript', 'c#', 'php', 'ruby', 'go', 'sql',
                    'devops', 'frontend', 'backend', 'fullstack', 'web', 'mobile',
                    '—Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä', '—Å–µ—Ç–µ–≤–æ–π –∏–Ω–∂–µ–Ω–µ—Ä', 'qa', '—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫',
                    'android', 'ios', '1c', '–±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö', '–∞–¥–º–∏–Ω'
                ],
                '–ú–µ–¥–∏—Ü–∏–Ω–∞': [
                    '–≤—Ä–∞—á', '–º–µ–¥—Å–µ—Å—Ç—Ä–∞', '—Ñ–µ–ª—å–¥—à–µ—Ä', '—Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥', '—Ö–∏—Ä—É—Ä–≥', '—Ç–µ—Ä–∞–ø–µ–≤—Ç',
                    '–ø–µ–¥–∏–∞—Ç—Ä', '–≥–∏–Ω–µ–∫–æ–ª–æ–≥', '–∫–∞—Ä–¥–∏–æ–ª–æ–≥', '–Ω–µ–≤—Ä–æ–ª–æ–≥', '–æ—Ñ—Ç–∞–ª—å–º–æ–ª–æ–≥',
                    '–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π', '–∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ', '–±–æ–ª—å–Ω–∏—Ü–∞', '–ø–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∞'
                ],
                '–ò–Ω–∂–µ–Ω–µ—Ä–∏—è': [
                    '–∏–Ω–∂–µ–Ω–µ—Ä', '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å', '–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤—â–∏–∫', '—Ç–µ—Ö–Ω–æ–ª–æ–≥', '–∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä',
                    '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫', '–º–µ—Ö–∞–Ω–∏–∫', '—ç–ª–µ–∫—Ç—Ä–∏–∫', '–ø—Ä–æ—Ä–∞–±', '–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä',
                    '—Ç–µ—Ö–Ω–∏–∫', '–º–æ–Ω—Ç–∞–∂', '–Ω–∞–ª–∞–¥–∫–∞', '–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ'
                ],
                '–≠–∫–æ–Ω–æ–º–∏–∫–∞': [
                    '—ç–∫–æ–Ω–æ–º–∏—Å—Ç', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π', '–∞–Ω–∞–ª–∏—Ç–∏–∫', '–º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥',
                    '–º–µ–Ω–µ–¥–∂–µ—Ä', '–∞—É–¥–∏—Ç–æ—Ä', '–∫—Ä–µ–¥–∏—Ç–Ω—ã–π', '–±–∞–Ω–∫', '—Ñ–∏–Ω–∞–Ω—Å—ã',
                    'accountant', 'finance', '–∞–Ω–∞–ª–∏–∑', '–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å'
                ],
                '–ü–µ–¥–∞–≥–æ–≥–∏–∫–∞': [
                    '—É—á–∏—Ç–µ–ª—å', '–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å', '–ø–µ–¥–∞–≥–æ–≥', '–≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—å', '–º–µ—Ç–æ–¥–∏—Å—Ç',
                    '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ', '—à–∫–æ–ª–∞', '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '–∫—É—Ä—Å', '–æ–±—É—á–µ–Ω–∏–µ'
                ],
                '–Æ—Ä–∏—Å–ø—Ä—É–¥–µ–Ω—Ü–∏—è': [
                    '—é—Ä–∏—Å—Ç', '–∞–¥–≤–æ–∫–∞—Ç', '—é—Ä–∏—Å–∫–æ–Ω—Å—É–ª—å—Ç', '–Ω–æ—Ç–∞—Ä–∏—É—Å', '—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å',
                    '–ø—Ä–∞–≤–æ–≤–µ–¥', '–∑–∞–∫–æ–Ω', '–¥–æ–≥–æ–≤–æ—Ä', '—Å—É–¥'
                ]
            }
            
            # –ü–æ–¥—Å—á–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            category_scores = {}
            for category, keywords in category_keywords.items():
                score = sum(1 for keyword in keywords if keyword in text)
                if score > 0:
                    category_scores[category] = score
            
            if category_scores:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                return max(category_scores.items(), key=lambda x: x[1])[0]
            else:
                return '–î—Ä—É–≥–æ–µ'
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {e}")
            return '–î—Ä—É–≥–æ–µ'

class RealDataEnhancer:
    """–£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é –ø–∞—Ä—Å–µ—Ä–∞"""
    
    def __init__(self):
        self.parser = HHApiParser()
    
    def enhance_with_real_vacancies(self, existing_vacancies=None, num_vacancies=50):
        """–î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∞–ª—å–Ω—ã–º–∏ –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ —Å —Ä–µ–∑–µ—Ä–≤–Ω—ã–º –ø–ª–∞–Ω–æ–º"""
        logger.info("üéØ –°–±–æ—Ä —Ä–µ–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π —Å HH.ru...")
        
        all_real_vacancies = []
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        search_queries = [
            "—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç", "it",
            "–≤—Ä–∞—á", "–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π", 
            "–∏–Ω–∂–µ–Ω–µ—Ä", 
            "–±—É—Ö–≥–∞–ª—Ç–µ—Ä", "—ç–∫–æ–Ω–æ–º–∏—Å—Ç",
            "—É—á–∏—Ç–µ–ª—å", "–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å",
            "—é—Ä–∏—Å—Ç"
        ]
        
        successful_queries = 0
        
        for query in search_queries:
            try:
                logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
                vacancies_df = self.parser.search_vacancies(
                    search_query=query, 
                    per_page=20,  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                    pages=1
                )
                
                if not vacancies_df.empty:
                    all_real_vacancies.append(vacancies_df)
                    successful_queries += 1
                    logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(vacancies_df)} –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}'")
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}'")
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{query}': {e}")
                continue
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if all_real_vacancies:
            real_vacancies_df = pd.concat(all_real_vacancies, ignore_index=True)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            if not real_vacancies_df.empty and 'id' in real_vacancies_df.columns:
                real_vacancies_df = real_vacancies_df.drop_duplicates(subset=['id'])
            
            logger.info(f"üéâ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ {len(real_vacancies_df)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            if existing_vacancies is not None and not existing_vacancies.empty:
                combined_df = pd.concat([existing_vacancies, real_vacancies_df], ignore_index=True)
                if 'id' in combined_df.columns:
                    combined_df = combined_df.drop_duplicates(subset=['id'])
                return combined_df
            else:
                return real_vacancies_df
        else:
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
            return self.get_fallback_vacancies(existing_vacancies)
    
    def get_fallback_vacancies(self, existing_vacancies=None):
        """–†–µ–∑–µ—Ä–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Å–ª—É—á–∞–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API"""
        try:
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            from data_provider import RealisticDataProvider
            provider = RealisticDataProvider()
            fallback_df = provider.generate_real_vacancies(30)
            
            # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            fallback_df['source'] = 'fallback'
            
            if existing_vacancies is not None and not existing_vacancies.empty:
                combined_df = pd.concat([existing_vacancies, fallback_df], ignore_index=True)
                return combined_df
            else:
                return fallback_df
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return pd.DataFrame()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
data_enhancer = RealDataEnhancer()

def test_api_connection():
    """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API HH"""
    try:
        parser = HHApiParser()
        test_response = parser.session.get("https://api.hh.ru/vacancies?text=test&per_page=1", timeout=10)
        
        if test_response.status_code == 200:
            logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API HH —É—Å–ø–µ—à–Ω–æ")
            return True
        else:
            logger.warning(f"‚ö†Ô∏è API –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {test_response.status_code}")
            return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API: {e}")
        return False

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–ê–†–°–ï–†–ê HH.RU")
    print("=" * 50)
    
    # –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    if test_api_connection():
        enhancer = RealDataEnhancer()
        vacancies = enhancer.enhance_with_real_vacancies(num_vacancies=20)
        
        print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}")
        if not vacancies.empty:
            print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            print(vacancies['category'].value_counts())
            print(f"üìã –ü—Ä–∏–º–µ—Ä—ã –≤–∞–∫–∞–Ω—Å–∏–π:")
            for i, (_, row) in enumerate(vacancies.head(3).iterrows()):
                print(f"{i+1}. {row.get('name', 'N/A')} - {row.get('company', 'N/A')} - {row.get('salary_avg_byn', 'N/A')} BYN")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API HH")